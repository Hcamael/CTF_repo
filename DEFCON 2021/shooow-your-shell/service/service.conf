service service
{
    socket_type = stream
    protocol    = tcp
    wait        = no
    user        = root
    bind        = 0.0.0.0
    server      = /wrapper
    type        = UNLISTED


    port        = 9090



    ###### Per-connection rlimits ####################################
    #
    # If you're using the default (private, NxN containers) these are
    # not very important. Prioritize k8s' limits (info.yml + manual).
    #
    # These are important if you opt for shared containers (quals-like
    # multiple teams trying to exploit the same container).

    # max number of "CPU seconds" (less than the wallclock timeout)
    rlimit_cpu = 60
    # internal memory limit -- also see the k8s limit in info.yml
    rlimit_as = 1024M

    # Leave this one in. Mostly innocuous, but could help if we need
    # to debug the container / in case of OOM / etc.
    nice = 2



    ###### xinetd's limit on concurrent instances ####################
    #
    # Again, not important for the private NxN container deployments

    # Do not have more than X instances at the same time
    # Note that the load balancer is NOT AWARE OF THIS, and so users will see failures (and the healthcheck)
    # will see failures. We have scripts to handle connection queues if useful, but
    # ideally this will never happen in prodction. POWs can be transparently required.
    instances = 64
    cps = 10000 10
    banner_fail = /banner_fail

    # Cannot use: per_source (that's the load balancer)
}
